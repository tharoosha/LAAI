{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent-classifier:\n",
    "Input:\n",
    " - Context and User input\n",
    "\n",
    "Categories: \n",
    "- Valid answer\n",
    "- Valid question\n",
    "- Request for help\n",
    "- Request for a hint\n",
    "- Expression of confusion\n",
    "- Boredom\n",
    "- Insult\n",
    "- Greeting\n",
    "- Misunderstanding\n",
    "- Clarification request\n",
    "\n",
    "Output:\n",
    "- Correct intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "You are an intent classifier. Given the input text, classify the intent into one of the following categories: No need of an explaination. \n",
    "- Valid answer : The user has provided a correct or appropriate response to a question or topic.\n",
    "- Valid question : The user has asked a clear and relevant question related to the context or discussion.\n",
    "- Irrelevent input : Using is providing a not relevent answer or asking a out-of-context question.\n",
    "- Boredom : The user is expressing a lack of interest, excitement, or engagement with the current topic or situation.\n",
    "- Insult : The user is using offensive or derogatory language directed at someone or something, showing disrespect.\n",
    "- Greeting : The user is initiating a conversation or interaction with a friendly or polite salutation, such as \"Hello\" or \"Good morning.\"\n",
    "- Clarification request : The user is asking for more information or a clearer explanation to better understand something they are confused about.\n",
    "\n",
    "Context: {context}\n",
    "User input: {user_input}\n",
    "\n",
    "Based on the above, output ONLY the final intent. \n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"user_input\"],  # These are the variables the template expects\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model = ChatGroq(\n",
    "    temperature=0.3,\n",
    "    model=\"llama3-70b-8192\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example context and user input\n",
    "context = \"The user has been working on an intent classifier for chatbot interactions.\"\n",
    "user_input = \"I'm not sure what this does, can you help me?\"\n",
    "\n",
    "# Use the prompt template to generate the final prompt\n",
    "final_prompt = prompt.format(context=context, user_input=user_input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clarification request'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = groq_model.invoke(final_prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent(context: str, user_input: str) -> str:\n",
    "    context = context\n",
    "    user_input = user_input\n",
    "\n",
    "    final_prompt = prompt.format(context=context, user_input=user_input)\n",
    "\n",
    "    response = groq_model.invoke(final_prompt)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting\n"
     ]
    }
   ],
   "source": [
    "print(get_intent(\n",
    "    context=\"James ordered a pizza. He ate 1/3 of the Pizza and his sister, Sandra ate 1/4 of the rest of the pizza. How much Pizza left\",\n",
    "    user_input=\"Hello how are you\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using Routing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "context=\"James ordered a pizza. He ate 1/3 of the Pizza and his sister, Sandra ate 1/4 of the rest of the pizza. How much Pizza left\"\n",
    "user_input=\"1/2\"\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "\n",
    "final_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"user_input\"],  # Define the variables expected\n",
    "    template=template  # This is your prompt string template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Prompt missing required variables: {'tools', 'tool_names', 'agent_scratchpad'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 56\u001b[0m\n\u001b[0;32m     50\u001b[0m final_prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m     51\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_input\u001b[39m\u001b[38;5;124m\"\u001b[39m],  \u001b[38;5;66;03m# Define the variables you expect in the prompt\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     template\u001b[38;5;241m=\u001b[39mtemplate  \u001b[38;5;66;03m# This is your prompt string\u001b[39;00m\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Create the ReAct agent using the groq_model, tools, and final prompt template\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroq_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_prompt_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Create an agent executor that will process the input using the tools and agent\u001b[39;00m\n\u001b[0;32m     59\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39mtools, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\featuren\\Lib\\site-packages\\langchain\\agents\\react\\agent.py:114\u001b[0m, in \u001b[0;36mcreate_react_agent\u001b[1;34m(llm, tools, prompt, output_parser, tools_renderer, stop_sequence)\u001b[0m\n\u001b[0;32m    110\u001b[0m missing_vars \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m}\u001b[38;5;241m.\u001b[39mdifference(\n\u001b[0;32m    111\u001b[0m     prompt\u001b[38;5;241m.\u001b[39minput_variables \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(prompt\u001b[38;5;241m.\u001b[39mpartial_variables)\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_vars:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    117\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools_renderer(\u001b[38;5;28mlist\u001b[39m(tools)),\n\u001b[0;32m    118\u001b[0m     tool_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([t\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools]),\n\u001b[0;32m    119\u001b[0m )\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_sequence:\n",
      "\u001b[1;31mValueError\u001b[0m: Prompt missing required variables: {'tools', 'tool_names', 'agent_scratchpad'}"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define the intent classifier template\n",
    "template = \"\"\"\n",
    "You are an intent classifier. Given the input text, classify the intent into one of the following categories: No need of an explanation. \n",
    "- Valid answer : The user has provided a correct or appropriate response to a question or topic.\n",
    "- Valid question : The user has asked a clear and relevant question related to the context or discussion.\n",
    "- Irrelevant input : User is providing an irrelevant answer or asking an out-of-context question.\n",
    "- Request for help : The user is explicitly asking for assistance or guidance to solve a problem or understand something.\n",
    "- Request for a hint : The user is seeking a small clue or suggestion to help them proceed with a task, without asking for the complete solution.\n",
    "- Expression of confusion : The user is indicating that they are uncertain or do not understand a concept, question, or situation.\n",
    "- Boredom : The user is expressing a lack of interest, excitement, or engagement with the current topic or situation.\n",
    "- Insult : The user is using offensive or derogatory language directed at someone or something, showing disrespect.\n",
    "- Greeting : The user is initiating a conversation or interaction with a friendly or polite salutation, such as \"Hello\" or \"Good morning.\"\n",
    "- Clarification request : The user is asking for more information or a clearer explanation to better understand something they are confused about.\n",
    "\n",
    "Context: {context}\n",
    "User input: {user_input}\n",
    "\n",
    "Based on the above, the correct intent is:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"user_input\"],  # These are the variables the template expects\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Initialize the language model (Groq model)\n",
    "groq_model = ChatGroq(\n",
    "    temperature=0.3,\n",
    "    model=\"llama3-70b-8192\",\n",
    ")\n",
    "\n",
    "# Example context and user input\n",
    "context = \"James ordered a pizza. He ate 1/3 of the Pizza and his sister, Sandra ate 1/4 of the rest of the pizza. How much Pizza left\"\n",
    "user_input = \"1/2\"\n",
    "\n",
    "# Create a TavilySearchResults tool as an example\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "# Create the final prompt template for the agent\n",
    "final_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"user_input\"],  # Define the variables you expect in the prompt\n",
    "    template=template  # This is your prompt string\n",
    ")\n",
    "\n",
    "# Create the ReAct agent using the groq_model, tools, and final prompt template\n",
    "agent = create_react_agent(groq_model, tools, final_prompt_template)\n",
    "\n",
    "# Create an agent executor that will process the input using the tools and agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Invoke the agent with context and user input\n",
    "response = agent_executor.invoke({\"context\": context, \"user_input\": user_input})\n",
    "\n",
    "# Print the output response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_executor.invoke()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
